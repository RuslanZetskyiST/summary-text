{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJE_CZEI4Q4d"
      },
      "source": [
        "# Stresczanie tekstów - Zespół nr 5\n",
        "\n",
        "Korzysta z modelu facebook/bart-large-cnn\n",
        "\n",
        "Tworzy streszczenia do 4 zdań okolo 150 wyrazów przy dłuższych tekstach\n",
        "\n",
        "Na razie tworzy streszczenia wyłącznie w języku angielskim\n",
        "\n",
        "(jeśli ktoś chce dodać to po prostu trzeba wrzucić tłumacza przed funkcja stresczania V3 oraz po niej)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75afc599"
      },
      "source": [
        "You can now use the `save_summary_to_txt(summary)` and `save_summary_to_pdf(summary)` functions with the `summary` variable after running the V3 flex cell. Uncomment the lines in the code above to use them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t3RjhSbZ5kig",
        "outputId": "fa1ad577-6c2d-4e49-d3d5-32674046a95d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "#Instalacja zasobów - WYMAGANA\n",
        "!pip install transformers sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQCETtcqsG_c",
        "outputId": "3a0fe28f-02b6-48d2-9d44-f36fa22d1a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SUMMARY ===\n",
            "Artificial intelligence (AI) has rapidly evolved from a theoretical concept to a transformative force reshaping nearly every sector of society. One major concern is the ethical implications of deploying AI in sensitive areas. Nations worldwide are investing heavily in AI research and development. The future of AI depends on how society chooses to guide its development.\n"
          ]
        }
      ],
      "source": [
        "#V3 flex\n",
        "!pip install transformers sentencepiece\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "def summarize_auto(text):\n",
        "\n",
        "    words = text.split()\n",
        "    n_words = len(words)\n",
        "\n",
        "    # próg - powyżej tego traktujemy tekst jako \"długi\"\n",
        "    LONG_THRESHOLD = 450\n",
        "\n",
        "    # -------------------------\n",
        "    # 1) KRÓTKI TEKST\n",
        "    # -------------------------\n",
        "    if n_words <= LONG_THRESHOLD:\n",
        "        summary = summarizer(\n",
        "            text,\n",
        "            max_length=150,\n",
        "            min_length=40,\n",
        "            do_sample=False\n",
        "        )\n",
        "        return summary[0][\"summary_text\"]\n",
        "\n",
        "    # -------------------------\n",
        "    # 2) DŁUGI TEKST\n",
        "    # -------------------------\n",
        "    def chunk_words(words, max_words=700):\n",
        "        for i in range(0, len(words), max_words):\n",
        "            yield \" \".join(words[i:i+max_words])\n",
        "\n",
        "    partial_summaries = []\n",
        "    for chunk in chunk_words(words):\n",
        "        s = summarizer(\n",
        "            chunk,\n",
        "            max_length=120,\n",
        "            min_length=40,\n",
        "            do_sample=False\n",
        "        )\n",
        "        partial_summaries.append(s[0][\"summary_text\"])\n",
        "\n",
        "    combined = \" \".join(partial_summaries)\n",
        "\n",
        "    final = summarizer(\n",
        "        combined,\n",
        "        max_length=150,\n",
        "        min_length=60,\n",
        "        do_sample=False\n",
        "    )\n",
        "\n",
        "    return final[0][\"summary_text\"]\n",
        "\n",
        "\n",
        "# =========================\n",
        "#   MIEJSCE NA TEKST\n",
        "# =========================\n",
        "text = \"\"\"Artificial intelligence (AI) has rapidly evolved from a theoretical concept to a transformative force reshaping nearly every sector of society. Its origins can be traced back to the mid-twentieth century, when pioneering researchers first began exploring the idea of creating machines capable of human-like reasoning. Over the decades, advancements in computer hardware, algorithm design, and data availability have propelled AI from simple rule-based systems to powerful learning models able to understand, predict, and generate complex patterns. Today, AI stands as a pivotal technology, influencing how individuals work, communicate, and even make decisions. One of the key milestones in AI development was the emergence of machine learning, a subset of AI focused on enabling machines to learn from data rather than relying on explicit programming. Traditional programming requires engineers to specify rules for every possible scenario. In contrast, machine learning models identify patterns within data and use these patterns to make decisions or predictions. This shift has enabled the creation of systems capable of performing tasks previously considered too complex for automation, such as image classification, speech recognition, and natural language understanding.\n",
        "\n",
        "Deep learning, an advanced form of machine learning, has been particularly instrumental in accelerating AI progress. Based on artificial neural networks inspired by the human brain, deep learning models have revolutionized fields like computer vision, natural language processing, and robotics. Neural networks consist of layers of interconnected nodes, each layer transforming the data in increasingly abstract ways. When trained on massive datasets, these networks learn hierarchical representations that allow them to perform highly sophisticated tasks. For example, convolutional neural networks (CNNs) excel at identifying objects in images, while recurrent neural networks (RNNs) and transformers have significantly improved language modeling and translation. AI has also made substantial inroads into healthcare, an industry traditionally resistant to technological change due to strict regulations and the need for accuracy. Machine learning models can analyze medical images to detect early signs of diseases such as cancer, often with accuracy comparable to or exceeding that of human specialists. Predictive algorithms assist clinicians by forecasting patient outcomes, identifying those at risk of complications, and recommending personalized treatment plans. Moreover, AI-powered systems have enhanced administrative efficiency by automating tasks like medical coding, appointment scheduling, and patient triage. These developments not only improve patient care but also reduce costs and alleviate workload pressures on healthcare professionals.\n",
        "\n",
        "In the business world, AI has become a critical tool for optimizing operations, improving customer engagement, and driving innovation. Companies use AI to automate routine processes, such as data entry and inventory management, enabling employees to focus on strategic activities. Customer service has been transformed by intelligent chatbots and virtual assistants capable of handling common inquiries and providing tailored support. Meanwhile, marketing teams leverage AI-driven analytics to better understand consumer behavior, segment audiences, and deliver personalized content that maximizes engagement and conversion rates. In manufacturing, AI-powered predictive maintenance systems monitor equipment in real time, identifying potential failures before they occur and preventing costly downtime. Despite these benefits, the rapid advancement of AI presents significant challenges that must be addressed to ensure its responsible use. One major concern is the ethical implications of deploying AI in sensitive areas such as law enforcement, hiring, and finance. Machine learning models are trained on historical data, which may contain biases that lead to unfair or discriminatory outcomes. For example, predictive policing algorithms can disproportionately target minority communities if trained on biased crime data. Similarly, automated hiring systems may favor applicants who resemble past successful candidates, perpetuating inequalities in the workforce. To mitigate these issues, researchers and policymakers are developing frameworks for ensuring transparency, accountability, and fairness in AI systems.\n",
        "\n",
        "Another challenge is the potential impact of AI on employment. While AI can enhance productivity and create new job opportunities, it can also automate roles previously performed by humans, leading to workforce displacement. Routine and repetitive tasks are particularly susceptible to automation, affecting industries such as manufacturing, transportation, and customer service. However, history suggests that technological progress ultimately creates more jobs than it eliminates, albeit after a period of adjustment. To minimize disruption, governments and organizations must invest in reskilling programs that prepare workers for the evolving job market. New roles are emerging in fields like data science, AI oversight, and human-machine collaboration, highlighting the importance of lifelong learning. Privacy is another major concern in the age of AI. Many AI systems rely on vast amounts of personal data to function effectively. This raises questions about how data is collected, stored, and used, as well as who has access to it. High-profile data breaches and misuse scandals have eroded public trust in organizations that handle sensitive information. To protect user privacy, companies must implement robust security measures, ensure compliance with regulations like GDPR, and adopt privacy-preserving techniques such as differential privacy and federated learning. These methods allow models to learn from data without exposing individual-level information, striking a balance between innovation and privacy protection.\n",
        "\n",
        "Additionally, the increasing sophistication of AI systems has brought concerns about transparency and explainability. Many advanced models, particularly deep learning networks, operate as “black boxes,” meaning their decision-making processes are difficult to interpret. This lack of explainability can be problematic in high-stakes environments where understanding the rationale behind a decision is essential. For instance, in healthcare or legal settings, professionals must be able to justify their actions, and opaque AI outputs can hinder this requirement. As a result, there is growing interest in explainable AI (XAI), a field focused on developing techniques that make AI more interpretable and trustworthy. The geopolitical implications of AI cannot be ignored either. Nations worldwide are investing heavily in AI research and development, recognizing its potential to drive economic growth and military capability. Countries like the United States and China are leading the race, competing for dominance in AI innovation, talent, and infrastructure. This competition has sparked concerns about national security, as advanced AI technologies could be weaponized or used for espionage. To foster global stability, international cooperation is needed to establish standards and agreements governing the development and use of AI. Collaborative efforts can help prevent misuse while promoting ethical and responsible innovation.\n",
        "\n",
        "Education is another area profoundly affected by AI. Intelligent tutoring systems can adapt to individual learning styles, providing personalized instruction that enhances student engagement and comprehension. Automated grading tools help teachers manage large volumes of assignments, allowing them to dedicate more time to interactive teaching. AI-driven analytics can identify students at risk of falling behind, enabling early interventions that support academic success. As AI becomes more prevalent in education, it is crucial to ensure that teachers receive adequate training and that technologies are implemented in ways that complement, rather than replace, human educators. Transportation is undergoing a transformation thanks to AI as well. Autonomous vehicles, once a futuristic concept, are now being tested on public roads and deployed in controlled environments. These vehicles rely on advanced perception systems, decision-making algorithms, and real-time data processing to navigate safely. While fully autonomous cars are not yet mainstream, the technology has already improved road safety through driver-assistance features like automatic braking, lane-keeping, and adaptive cruise control. As the technology matures, it has the potential to reduce traffic accidents, alleviate congestion, and enhance mobility for individuals unable to drive.\n",
        "\n",
        "In the realm of entertainment, AI has opened new possibilities for creativity and engagement. Streaming platforms use AI to recommend content based on user preferences, increasing satisfaction and retention. Video game developers employ AI to create dynamic and responsive environments that adapt to player behavior. Additionally, generative AI models can produce art, music, and narratives, challenging traditional notions of creativity and raising philosophical questions about the nature of artistic expression. These advancements demonstrate AI’s capacity to enhance human creativity rather than replace it. Environmental conservation efforts are also benefiting from AI. Scientists use machine learning to analyze satellite imagery, monitor wildlife populations, and track changes in ecosystems. AI-powered models can predict natural disasters, such as hurricanes and wildfires, enabling more effective response strategies. In agriculture, AI helps optimize resource usage by analyzing soil conditions, weather patterns, and crop health. These applications contribute to more sustainable practices that protect the planet for future generations.\n",
        "\n",
        "As AI continues to evolve, the need for comprehensive regulation becomes increasingly important. Policymakers must balance the potential benefits of AI with the risks, ensuring that innovation proceeds responsibly. Regulations should promote transparency, protect individual rights, and prevent harmful uses of the technology. However, overly restrictive rules could hinder progress, making it essential to engage stakeholders from academia, industry, and civil society in the regulatory process. Collaborative governance models can help create flexible frameworks that adapt to the rapid pace of technological change. Ultimately, the future of AI depends on how society chooses to guide its development. With thoughtful planning, ethical considerations, and a commitment to inclusivity, AI has the potential to improve quality of life, solve complex global challenges, and unlock new possibilities. However, if left unchecked, it could exacerbate inequalities, compromise privacy, and create unintended consequences. By fostering a culture of responsible innovation, humanity can harness the power of AI while safeguarding its values and interests. The journey ahead requires collaboration, foresight, and a shared vision of a future where technology serves the greater good.\n",
        "\"\"\"\n",
        "\n",
        "summary = summarize_auto(text)\n",
        "print(\"=== SUMMARY ===\")\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "744760b8"
      },
      "outputs": [],
      "source": [
        "#obsługa pdf SK\n",
        "!pip install fpdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ed880a6"
      },
      "outputs": [],
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "def save_summary_to_txt(summary_text, filename=\"summary.txt\"):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(summary_text)\n",
        "    print(f\"Summary saved to {filename}\")\n",
        "\n",
        "def save_summary_to_pdf(summary_text, filename=\"summary.pdf\"):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(0, 10, summary_text.encode('latin-1', 'replace').decode('latin-1'))\n",
        "    pdf.output(filename)\n",
        "    print(f\"Summary saved to {filename}\")\n",
        "\n",
        "# Ensure 'summary' variable is defined for testing purposes if not already in global scope\n",
        "if 'summary' not in globals():\n",
        "    summary = \"This is a sample summary text to test the save functionality. It will be saved as either a TXT or PDF file based on user input.\"\n",
        "\n",
        "# Interactive prompt for saving the summary\n",
        "print(\"\\n--- Save Summary ---\")\n",
        "file_format = input(\"Enter the desired save format (txt or pdf): \").lower()\n",
        "\n",
        "if file_format == 'txt':\n",
        "    save_summary_to_txt(summary)\n",
        "elif file_format == 'pdf':\n",
        "    save_summary_to_pdf(summary)\n",
        "else:\n",
        "    print(\"Invalid format selected. Summary will not be saved. Please choose 'txt' or 'pdf'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "9385b963"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "import string\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# KONFIGURACJA JĘZYKÓW\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "LANG_CONFIG = {\n",
        "    \"pl\": {\n",
        "        \"name\": \"polski\",\n",
        "        \"markers\": [r'znaczenia', r'rzeczownik', r'czasownik', r'przymiotnik', r'wyrażenie'],\n",
        "    },\n",
        "    \"de\": {\n",
        "        \"name\": \"Deutsch\",\n",
        "        \"markers\": [r'Bedeutungen', r'Substantiv', r'Verb', r'Adjektiv'],\n",
        "    },\n",
        "    \"es\": {\n",
        "        \"name\": \"Español\",\n",
        "        \"markers\": [r'Sustantivo', r'Verbo', r'Adjetivo', r'Forma verbal'],\n",
        "    },\n",
        "    \"en\": {\n",
        "        \"name\": \"English\",\n",
        "        \"markers\": [r'Noun', r'Verb', r'Adjective', r'Definition'],\n",
        "    },\n",
        "}\n",
        "\n",
        "STOPWORDS = {\n",
        "    \"pl\": set([\"i\",\"oraz\",\"w\",\"na\",\"do\",\"o\",\"że\",\"a\",\"to\",\"jest\",\"z\",\"się\"]),\n",
        "    \"de\": set([\"und\",\"oder\",\"die\",\"der\",\"das\",\"ein\",\"eine\",\"ist\",\"zu\",\"vom\",\"im\"]),\n",
        "    \"es\": set([\"y\",\"o\",\"de\",\"la\",\"el\",\"que\",\"es\",\"en\",\"un\",\"una\"]),\n",
        "    \"en\": set([\"and\",\"or\",\"the\",\"is\",\"are\",\"of\",\"to\",\"in\",\"for\",\"on\",\"with\"]),\n",
        "}\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# FUNKCJA 1 — WYBIERANIE TRUDNYCH SŁÓW\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def extract_difficult_words(text, lang=\"en\"):\n",
        "    \"\"\"Zwraca listę trudnych słów (nie-stopwords, alfabetyczne, powyżej 5 liter).\"\"\"\n",
        "\n",
        "    words = [\n",
        "        w.strip(string.punctuation).lower()\n",
        "        for w in text.split()\n",
        "        if w.strip(string.punctuation)\n",
        "    ]\n",
        "\n",
        "    stop = STOPWORDS.get(lang, set())\n",
        "\n",
        "    difficult = [\n",
        "        w for w in words\n",
        "        if len(w) > 5 and w not in stop and w.isalpha()\n",
        "    ]\n",
        "\n",
        "    return list(sorted(set(difficult)))\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# FUNKCJA 2 — POBIERANIE DEFINICJI Z WIKISŁOWNIKA\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def get_definitions(words, lang=\"en\"):\n",
        "    \"\"\"Zwraca definicje słów w danym języku.\"\"\"\n",
        "    result = {}\n",
        "    cfg = LANG_CONFIG[lang]\n",
        "\n",
        "    markers_regex = re.compile(\"|\".join(cfg[\"markers\"]), re.IGNORECASE)\n",
        "\n",
        "    for word in words:\n",
        "\n",
        "        url = f\"https://{lang}.wiktionary.org/w/api.php\"\n",
        "        params = {\n",
        "            \"action\": \"query\",\n",
        "            \"prop\": \"extracts\",\n",
        "            \"titles\": word,\n",
        "            \"format\": \"json\",\n",
        "            \"explaintext\": True,\n",
        "            \"redirects\": True,\n",
        "            \"utf8\": True\n",
        "        }\n",
        "        headers = {\"User-Agent\": \"DefinitionBot/1.0 (example@example.com)\"}\n",
        "\n",
        "        try:\n",
        "            r = requests.get(url, params=params, headers=headers)\n",
        "            r.raise_for_status()\n",
        "            data = r.json()\n",
        "\n",
        "            page_id = next(iter(data[\"query\"][\"pages\"]))\n",
        "            if page_id == \"-1\":\n",
        "                result[word] = [\"Brak definicji.\"]\n",
        "                continue\n",
        "\n",
        "            extract = data[\"query\"][\"pages\"][page_id][\"extract\"]\n",
        "            if not extract:\n",
        "                result[word] = [\"Brak treści w artykule.\"]\n",
        "                continue\n",
        "\n",
        "            lines = extract.split(\"\\n\")\n",
        "\n",
        "            in_lang_section = False\n",
        "            in_def_block = False\n",
        "            definitions = []\n",
        "\n",
        "            lang_header = re.compile(\n",
        "                rf\"^==\\s*{cfg['name']}\\s*==$|^==\\s*język {cfg['name']}\\s*==$\",\n",
        "                re.IGNORECASE\n",
        "            )\n",
        "\n",
        "            for line in lines:\n",
        "                stripped = line.strip()\n",
        "\n",
        "                # wykrycie sekcji językowej\n",
        "                if re.match(r\"^==[^=]+==$\", stripped):\n",
        "                    if lang_header.match(stripped):\n",
        "                        in_lang_section = True\n",
        "                        in_def_block = False\n",
        "                    else:\n",
        "                        in_lang_section = False\n",
        "                    continue\n",
        "\n",
        "                if not in_lang_section:\n",
        "                    continue\n",
        "\n",
        "                # wejście w blok definicji\n",
        "                if markers_regex.search(stripped):\n",
        "                    in_def_block = True\n",
        "                    continue\n",
        "\n",
        "                if in_def_block:\n",
        "                    # czyszczenie treści\n",
        "                    clean = re.sub(r'\\{\\{.*?\\}\\}', '', stripped)\n",
        "                    clean = re.sub(r'\\[\\[(.*?)\\|(.*?)\\]\\]', r'\\2', clean)\n",
        "                    clean = re.sub(r'\\[\\[(.*?)\\]\\]', r'\\1', clean).strip()\n",
        "\n",
        "                    # definicje numeryczne lub listy\n",
        "                    if re.match(r\"^\\d+\\.\\s\", clean) or re.match(r\"^[\\*\\-]\\s\", clean):\n",
        "                        if len(clean) > 5:\n",
        "                            definitions.append(clean)\n",
        "\n",
        "            # fallback — pierwszy akapit\n",
        "            if not definitions:\n",
        "                first = next(\n",
        "                    (l.strip() for l in lines if len(l.strip()) > 40 and not l.startswith(\"==\")),\n",
        "                    None\n",
        "                )\n",
        "                if first:\n",
        "                    definitions = [first]\n",
        "                else:\n",
        "                    definitions = [\"Nie udało się odczytać definicji.\"]\n",
        "\n",
        "            result[word] = definitions[:5]\n",
        "\n",
        "        except Exception as e:\n",
        "            result[word] = [f\"Błąd: {e}\"]\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# FUNKCJA 3 — ZWRACA WIELOJĘZYCZNE DEFINICJE\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def get_multilang_definitions(words, languages=[\"pl\", \"de\", \"en\", \"es\"]):\n",
        "    out = {}\n",
        "\n",
        "    for w in words:\n",
        "        out[w] = {}\n",
        "        for lang in languages:\n",
        "            defs = get_definitions([w], lang)\n",
        "            out[w][lang] = defs[w]\n",
        "\n",
        "    return out\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
